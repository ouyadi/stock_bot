import warnings
# å¿½ç•¥ duckduckgo_search çš„åŒ…æ›´åè­¦å‘Š
warnings.filterwarnings("ignore", category=RuntimeWarning, message="This package.*duckduckgo_search.*")
import discord
from discord.ext import commands
import yfinance as yf
import pandas as pd
import numpy as np
from openai import OpenAI
import os
import asyncio
from http.server import HTTPServer, BaseHTTPRequestHandler
import threading
import socket
from duckduckgo_search import DDGS
from scipy.stats import norm
import datetime
import io
import re
from reportlab.lib.pagesizes import letter
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.cidfonts import UnicodeCIDFont
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image
from reportlab.graphics.shapes import Drawing, Line
from reportlab.lib import colors
import matplotlib
matplotlib.use('Agg') # è®¾ç½®åç«¯ä¸º Aggï¼Œé€‚ç”¨äºæ— å¤´æœåŠ¡å™¨ç¯å¢ƒ
import matplotlib.pyplot as plt
import json
import time
from supabase import create_client, Client
import uvicorn
from fastapi import FastAPI, Form, File, UploadFile, HTTPException, Body, Request, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field
import base64
from lxml import html as lxml_html
import PyPDF2
try:
    from PIL import Image as PILImage, ImageEnhance
    import pytesseract
except ImportError:
    PILImage = None
    ImageEnhance = None
    pytesseract = None

# ================= é…ç½®åŒºåŸŸ =================
# å»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œæˆ–è€…ç›´æ¥åœ¨æ­¤å¤„å¡«å…¥ Key
DISCORD_TOKEN = os.getenv('DISCORD_TOKEN')
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')
DISCORD_AI_REPORT_CHANNEL_ID = os.getenv('DISCORD_AI_REPORT_CHANNEL_ID') # æŒ‡å®šé¢‘é“ ID
INSTITUTION_REPORT_CHANNEL_ID = '1434770162573250560' # æŠ•ç ”æœºæ„å¸¦é£é¢‘é“
SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_KEY')
SUPABASE_BUCKET = os.getenv('SUPABASE_BUCKET', 'reports') # é»˜è®¤ bucket åä¸º reports


# é…ç½® DeepSeek AI
client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url="https://api.deepseek.com")
MODEL_ID = 'deepseek-reasoner'

# é…ç½® Discord Bot
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix='!', intents=intents)

# é…ç½® Supabase
supabase: Client = None
if SUPABASE_URL and SUPABASE_KEY:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# é…ç½® FastAPI
app = FastAPI()

# é…ç½® CORS (å…è®¸å‰ç«¯è·¨åŸŸè°ƒç”¨)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æºï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®é™åˆ¶ä¸ºå‰ç«¯åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ================= æŠ•ç ”æŠ¥å‘Šå¤„ç†æ¨¡å— =================

class ResearchAnalyzer:
    @staticmethod
    async def summarize_content(content: str, subject: str) -> str:
        """ä½¿ç”¨ DeepSeek API å¯¹æŠ•ç ”æŠ¥å‘Šå†…å®¹è¿›è¡Œæ€»ç»“"""
        prompt = f"""
        # Role
        ä½ æ˜¯ä¸€åé¡¶å°–çš„é‡‘èåˆ†æå¸ˆï¼Œä½ çš„ä»»åŠ¡æ˜¯é˜…è¯»å¹¶æ€»ç»“ä¸€ä»½æ¥è‡ªæŠ•ç ”æœºæ„çš„ç”µå­é‚®ä»¶æŠ¥å‘Šã€‚

        # Task
        è¯·æ ¹æ®æŠ¥å‘Šå†…å®¹ï¼Œç”Ÿæˆä¸€ä»½ç²¾ç‚¼ã€ä¸“ä¸šçš„æ‘˜è¦ã€‚
        **æ³¨æ„ï¼šè¯·å¿½ç•¥æŠ¥å‘Šæœ«å°¾æˆ–æ–‡ä¸­å‡ºç°çš„æ³•å¾‹å…è´£å£°æ˜ (Disclaimer)ã€é£é™©æŠ«éœ² (Risk Disclosure) ç­‰åˆè§„æ€§æ–‡æœ¬ï¼Œä¸“æ³¨äºå®è´¨æ€§çš„æŠ•èµ„åˆ†æå†…å®¹ã€‚**
        æ‘˜è¦åº”åŒ…å«ä»¥ä¸‹å‡ ç‚¹ï¼š
        1.  **æ ¸å¿ƒè§‚ç‚¹ (Core Thesis)**: æŠ¥å‘Šæœ€å…³é”®çš„ç»“è®ºæ˜¯ä»€ä¹ˆï¼Ÿ(ä¾‹å¦‚: çœ‹å¤š/çœ‹ç©ºæŸèµ„äº§ã€å¸‚åœºè¶‹åŠ¿é¢„æµ‹ç­‰)
        2.  **å…³é”®è®ºæ® (Key Arguments)**: æ”¯æ’‘æ ¸å¿ƒè§‚ç‚¹çš„ä¸‰åˆ°äº”ä¸ªæœ€é‡è¦çš„æ•°æ®ã€äº‹ä»¶æˆ–é€»è¾‘æ˜¯ä»€ä¹ˆï¼Ÿ
        3.  **æ½œåœ¨é£é™© (Potential Risks)**: æŠ¥å‘Šä¸­æåŠäº†å“ªäº›å¯èƒ½å¯¼è‡´ç»“è®ºå¤±æ•ˆçš„é£é™©å› ç´ ï¼Ÿ
        4.  **ç›®æ ‡ä»·ä¸è¯„çº§ (Target & Rating)**: å¦‚æœæŠ¥å‘Šä¸­æ˜ç¡®ç»™å‡ºäº†ç›®æ ‡ä»·æˆ–æŠ•èµ„è¯„çº§(å¦‚ä¹°å…¥/æŒæœ‰/å–å‡º)ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºã€‚

        è¯·ä½¿ç”¨ä¸­æ–‡æ’°å†™ï¼Œè¯­è¨€é£æ ¼è¦ä¸“ä¸šã€å®¢è§‚ã€æ¡ç†æ¸…æ™°ã€‚

        # Input Data
        - **é‚®ä»¶ä¸»é¢˜**: {subject}
        - **æŠ¥å‘Šå†…å®¹**:
        ---
        {content[:50000]} 
        ---
        """
        try:
            loop = asyncio.get_running_loop()
            response = await loop.run_in_executor(
                None,
                lambda: client.chat.completions.create(
                    model=MODEL_ID,
                    messages=[{"role": "user", "content": prompt}],
                    stream=False
                )
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"DeepSeek Error: {e}")
            return f"AI æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}"

    @staticmethod
    def create_summary_pdf(summary_text: str, subject: str) -> io.BytesIO:
        """å°† AI ç”Ÿæˆçš„æ‘˜è¦è½¬æ¢ä¸º PDF"""
        try:
            buffer = io.BytesIO()
            doc = SimpleDocTemplate(buffer, pagesize=letter, rightMargin=72, leftMargin=72, topMargin=72, bottomMargin=72)
            styles = getSampleStyleSheet()
            pdfmetrics.registerFont(UnicodeCIDFont('STSong-Light'))

            title_style = ParagraphStyle('Title', fontName='STSong-Light', fontSize=18, alignment=1, spaceAfter=20, textColor=colors.navy)
            normal_style = ParagraphStyle('Normal', fontName='STSong-Light', fontSize=11, leading=14, spaceAfter=6)
            bullet_style = ParagraphStyle('Bullet', parent=normal_style, leftIndent=10)
            
            story = []
            story.append(Paragraph(f"æŠ•ç ”æŠ¥å‘Šæ‘˜è¦: {subject}", title_style))
            
            # ç®€å•çš„ Markdown è§£æ
            for line in summary_text.split('\n'):
                line = line.strip()
                if line.startswith('#'):
                    story.append(Paragraph(line.lstrip('#').strip(), ParagraphStyle('h2', parent=normal_style, fontSize=14, spaceBefore=10)))
                elif line.startswith('- ') or line.startswith('* '):
                    story.append(Paragraph(f"â€¢ {line[2:]}", bullet_style))
                elif line:
                    story.append(Paragraph(line, normal_style))

            doc.build(story)
            buffer.seek(0)
            return buffer
        except Exception as e:
            print(f"PDF Creation Error: {e}")
            return None

    @staticmethod
    async def send_discord_notification(summary: str, subject: str, pdf_url: str, status_msg: Optional[discord.Message] = None):
        """å‘é€é€šçŸ¥åˆ°æŒ‡å®šçš„ Discord é¢‘é“"""
        channel_id = int(INSTITUTION_REPORT_CHANNEL_ID) # æŠ•ç ”æœºæ„å¸¦é£é¢‘é“
        channel = bot.get_channel(channel_id)
        if not channel:
            print(f"é”™è¯¯: æ‰¾ä¸åˆ°é¢‘é“ ID {channel_id}")
            return

        embed = discord.Embed(
            title=f"ğŸ“¬ æ–°æŠ•ç ”æŠ¥å‘Šæ‘˜è¦: {subject}",
            description=summary,
            color=discord.Color.blue()
        )
        embed.add_field(name="ä¸‹è½½å®Œæ•´ PDF æŠ¥å‘Š", value=f"[ç‚¹å‡»è¿™é‡Œ]({pdf_url})", inline=False)
        embed.set_footer(text="ç”± CloudMailIn -> DeepSeek -> Supabase é©±åŠ¨")
        
        if status_msg:
            await status_msg.edit(content="", embed=embed)
        else:
            await channel.send(embed=embed)


# å®šä¹‰ CloudMailIn çš„æ•°æ®æ¨¡å‹
class CloudmailinAttachment(BaseModel):
    file_name: str
    content_type: str
    content: str  # Base64 encoded content
    size: int

class CloudmailinPayload(BaseModel):
    plain: Optional[str] = None
    html: Optional[str] = None
    subject: Optional[str] = "æ— ä¸»é¢˜"
    attachments: List[CloudmailinAttachment] = []

async def process_email_task(payload: CloudmailinPayload):
    """åå°å¼‚æ­¥å¤„ç†é‚®ä»¶ä»»åŠ¡"""
    subject = payload.subject
    print(f"ğŸ”„ åå°ä»»åŠ¡å¯åŠ¨: å¤„ç†é‚®ä»¶ '{subject}'")
    
    # === å‘é€åˆå§‹çŠ¶æ€æ¶ˆæ¯ ===
    status_msg = None
    try:
        channel_id = int(INSTITUTION_REPORT_CHANNEL_ID)
        channel = bot.get_channel(channel_id)
        if channel:
            status_msg = await channel.send(f"ğŸ“§ æ”¶åˆ°æ–°é‚®ä»¶: **{subject}**\nâ³ æ­£åœ¨è§£æé™„ä»¶ä¸æ­£æ–‡...")
    except Exception as e:
        print(f"Discord status update failed: {e}")

    analysis_content = ""
    source = ""

    # 1. æå–å†…å®¹ (èšåˆæ‰€æœ‰æ¥æº: æ­£æ–‡ + PDF + å›¾ç‰‡æç¤º)
    parts = []
    sources = []

    try:
        # --- å¤„ç†é‚®ä»¶æ­£æ–‡ ---
        body_text = ""
        if payload.html:
            try:
                # ä½¿ç”¨ lxml æ¸…ç† HTML æ ‡ç­¾
                doc = lxml_html.fromstring(payload.html)
                # ç§»é™¤è„šæœ¬å’Œæ ·å¼
                for bad in doc.xpath("//script | //style"):
                    bad.getparent().remove(bad)
                body_text = doc.text_content().strip()
                if body_text:
                    sources.append("HTMLæ­£æ–‡")
            except Exception as e:
                print(f"HTML parsing warning: {e}")
        
        # å¦‚æœ HTML è§£æå¤±è´¥æˆ–ä¸ºç©ºï¼Œå°è¯•çº¯æ–‡æœ¬
        if not body_text and payload.plain:
            body_text = payload.plain.strip()
            if body_text:
                sources.append("çº¯æ–‡æœ¬æ­£æ–‡")
        
        if body_text:
            parts.append(f"=== é‚®ä»¶æ­£æ–‡ ===\n{body_text}")

        # --- å¤„ç† PDF é™„ä»¶ ---
        pdf_attachments = [a for a in payload.attachments if "pdf" in a.content_type]
        for pdf in pdf_attachments:
            try:
                print(f"ğŸ“„ å¤„ç† PDF é™„ä»¶: {pdf.file_name}")
                pdf_content = base64.b64decode(pdf.content)
                pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_content))
                pdf_text = ""
                for page in pdf_reader.pages:
                    pdf_text += page.extract_text() or ""
                
                if pdf_text.strip():
                    parts.append(f"=== PDFé™„ä»¶: {pdf.file_name} ===\n{pdf_text}")
                    sources.append(f"PDF:{pdf.file_name}")
            except Exception as e:
                print(f"PDF reading error ({pdf.file_name}): {e}")

        # --- å¤„ç†å›¾ç‰‡é™„ä»¶ ---
        image_attachments = []
        for a in payload.attachments:
            # å¢å¼ºåˆ¤æ–­ï¼šå¦‚æœ Content-Type ä¸¢å¤±æˆ–ä¸º octet-streamï¼Œå°è¯•é€šè¿‡åç¼€åè¯†åˆ«
            if "image" in a.content_type.lower() or \
               any(a.file_name.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp', '.heic']):
                image_attachments.append(a)

        for img in image_attachments:
            if PILImage and pytesseract:
                try:
                    print(f"ğŸ–¼ï¸ æ­£åœ¨OCRè¯†åˆ«å›¾ç‰‡: {img.file_name}")
                    img_content = base64.b64decode(img.content)
                    image = PILImage.open(io.BytesIO(img_content))
                    
                    # === OCR é¢„å¤„ç†ä¼˜åŒ– ===
                    # 1. è½¬ä¸ºç°åº¦å›¾ (æ¶ˆé™¤è‰²å½©å¹²æ‰°)
                    image = image.convert('L')
                    
                    # 2. å¢å¼ºå¯¹æ¯”åº¦ (è®©æ–‡å­—æ›´æ¸…æ™°)
                    if ImageEnhance:
                        enhancer = ImageEnhance.Contrast(image)
                        image = enhancer.enhance(2.0) # æé«˜å¯¹æ¯”åº¦

                    # 3. æ”¾å¤§å›¾ç‰‡ (Tesseract å¯¹å°å­—å·è¯†åˆ«è¾ƒå·®ï¼Œæ”¾å¤§æœ‰åŠ©äºè¯†åˆ«)
                    width, height = image.size
                    if width < 1000:
                        image = image.resize((width * 2, height * 2), PILImage.Resampling.LANCZOS)

                    # === Tesseract é…ç½® ===
                    # --psm 6: å‡è®¾æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„æ–‡æœ¬å—ã€‚è¿™å¯¹è¡¨æ ¼ç‰¹åˆ«æœ‰æ•ˆï¼Œå› ä¸ºå®ƒä¼šæŒ‰è¡Œè¯»å–ï¼Œè€Œä¸æ˜¯è¯•å›¾åˆ†æ ã€‚
                    custom_config = r'--oem 3 --psm 6'

                    # å°è¯•è¯†åˆ«ä¸­æ–‡å’Œè‹±æ–‡ï¼Œå¦‚æœå¤±è´¥åˆ™å›é€€åˆ°é»˜è®¤è¯­è¨€
                    try:
                        text = pytesseract.image_to_string(image, lang='chi_sim+eng', config=custom_config)
                    except Exception:
                        text = pytesseract.image_to_string(image, config=custom_config)
                    
                    if text.strip():
                        parts.append(f"=== å›¾ç‰‡é™„ä»¶ ({img.file_name}) OCRå†…å®¹ ===\n{text}")
                        sources.append(f"OCR:{img.file_name}")
                except Exception as e:
                    print(f"OCR Error ({img.file_name}): {e}")
            else:
                parts.append(f"=== å›¾ç‰‡é™„ä»¶ ({img.file_name}) ===\n[æœåŠ¡å™¨æœªå®‰è£… OCR åº“ï¼Œæ— æ³•æå–æ–‡å­—]")
                if "å›¾ç‰‡(æœªOCR)" not in sources: sources.append("å›¾ç‰‡(æœªOCR)")

        if not parts:
            print("âŒ é‚®ä»¶å†…å®¹ä¸ºç©º")
            if status_msg:
                try: await status_msg.edit(content=f"âŒ å¤„ç†é‚®ä»¶ **{subject}** å¤±è´¥: é‚®ä»¶å†…å®¹ä¸ºç©º")
                except: pass
            return

        analysis_content = "\n\n".join(parts)
        source = ", ".join(sources)
        print(f"ğŸ“ æ±‡æ€»å†…å®¹æ¥æº: {source}")
        
        if status_msg:
            try: await status_msg.edit(content=f"ğŸ“§ æ”¶åˆ°æ–°é‚®ä»¶: **{subject}**\nğŸ“ å†…å®¹æå–å®Œæˆ ({source})ï¼Œæ­£åœ¨è°ƒç”¨ DeepSeek è¿›è¡Œæ·±åº¦åˆ†æ...")
            except: pass

        # 2. è°ƒç”¨ AI è¿›è¡Œæ€»ç»“
        print("ğŸ¤– æ­£åœ¨å‘é€å†…å®¹åˆ° DeepSeek è¿›è¡Œæ€»ç»“...")
        if not analysis_content.strip():
             summary_text = "æŠ¥å‘Šå†…å®¹ä¸ºç©ºæˆ–æ— æ³•è§£æã€‚"
        else:
             summary_text = await ResearchAnalyzer.summarize_content(analysis_content, payload.subject)
        
        if status_msg:
            try: await status_msg.edit(content=f"ğŸ“§ æ”¶åˆ°æ–°é‚®ä»¶: **{subject}**\nğŸ¤– AI åˆ†æå®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆ PDF æŠ¥å‘Š...")
            except: pass

        # 3. ç”Ÿæˆ PDF
        print("ğŸ“‘ æ­£åœ¨ç”Ÿæˆæ‘˜è¦ PDF...")
        pdf_buffer = ResearchAnalyzer.create_summary_pdf(summary_text, payload.subject)
        
        if not pdf_buffer:
            print("âŒ æ— æ³•ç”Ÿæˆ PDF")
            if status_msg:
                try: await status_msg.edit(content=f"âŒ å¤„ç†é‚®ä»¶ **{subject}** å¤±è´¥: æ— æ³•ç”Ÿæˆ PDF")
                except: pass
            return
            
        if status_msg:
            try: await status_msg.edit(content=f"ğŸ“§ æ”¶åˆ°æ–°é‚®ä»¶: **{subject}**\nâ˜ï¸ PDF ç”Ÿæˆå®Œæ¯•ï¼Œæ­£åœ¨ä¸Šä¼ è‡³ Supabase...")
            except: pass

        # 4. ä¸Šä¼ åˆ° Supabase
        print("â˜ï¸ æ­£åœ¨ä¸Šä¼  PDF åˆ° Supabase...")
        pdf_filename = f"report_summary_{int(time.time())}.pdf"
        public_url = "Supabase not configured"
        if supabase:
            res = supabase.storage.from_(SUPABASE_BUCKET).upload(
                file=pdf_buffer.getvalue(), 
                path=pdf_filename, 
                file_options={"content-type": "application/pdf"}
            )
            public_url = supabase.storage.from_(SUPABASE_BUCKET).get_public_url(pdf_filename)

        # 5. å‘é€åˆ° Discord
        print("ğŸ’¬ æ­£åœ¨å‘é€é€šçŸ¥åˆ° Discord...")
        await ResearchAnalyzer.send_discord_notification(summary_text, payload.subject, public_url, status_msg)

        print("âœ… æŠ•ç ”æŠ¥å‘Šå¤„ç†æµç¨‹å®Œæˆ!")

    except Exception as e:
        print(f"å¤„ç†é‚®ä»¶æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        if status_msg:
            try: await status_msg.edit(content=f"âŒ å¤„ç†é‚®ä»¶ **{subject}** æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            except: pass

@app.post("/email-report")
async def handle_email_report(request: Request, background_tasks: BackgroundTasks):
    """
    æ¥æ”¶æ¥è‡ª CloudMailIn çš„é‚®ä»¶ POST è¯·æ±‚ï¼Œè¿›è¡Œå¤„ç†å’Œè½¬å‘ã€‚
    """
    print("ğŸ“§ æ”¶åˆ°æ–°é‚®ä»¶è¯·æ±‚...")
    content_type = request.headers.get("content-type", "")
    payload = None
    subject = "æœªçŸ¥ä¸»é¢˜"

    # === 1. è§£æè¯·æ±‚æ•°æ® (æ”¯æŒ JSON å’Œ Multipart) ===
    if "application/json" in content_type:
        # å¤„ç† Google Script å‘é€çš„ JSON
        try:
            data = await request.json()
            print("ğŸ” è§£æ JSON Payload (Google Script)")
            
            subject = data.get("subject", "æ— ä¸»é¢˜")
            plain = data.get("body")
            html = None # Google Script é€šå¸¸åªå‘é€ getPlainBody
            
            attachments_list = []
            for att in data.get("attachments", []):
                content_b64 = att.get("content", "")
                attachments_list.append(CloudmailinAttachment(
                    file_name=att.get("fileName", "unknown"),
                    content_type=att.get("mimeType", "application/octet-stream"),
                    content=content_b64,
                    size=len(content_b64)
                ))
            
            payload = CloudmailinPayload(
                plain=plain,
                html=html,
                subject=subject,
                attachments=attachments_list
            )
        except Exception as e:
            print(f"JSON Parse Error: {e}")
            raise HTTPException(status_code=400, detail=f"JSON parsing error: {e}")
    else:
        # å¤„ç† CloudMailIn å‘é€çš„ Multipart Form Data
        try:
            form = await request.form()
            print(f"ğŸ” Form Keys: {list(form.keys())}")
            
            plain = form.get("plain")
            html = form.get("html")
            subject = form.get("headers[subject]") or form.get("subject") or "æ— ä¸»é¢˜"
            
            attachments_list = []
            for key, value in form.multi_items():
                if isinstance(value, UploadFile) or (hasattr(value, "filename") and value.filename):
                    print(f"ğŸ“‚ æ”¶åˆ°é™„ä»¶: {value.filename} (Key: {key}, Content-Type: {value.content_type})")
                    try:
                        content = await value.read()
                        if content:
                            b64_content = base64.b64encode(content).decode('utf-8')
                            attachments_list.append(CloudmailinAttachment(
                                file_name=value.filename or "unknown",
                                content_type=value.content_type or "application/octet-stream",
                                content=b64_content,
                                size=len(content)
                            ))
                    finally:
                        await value.close()
                elif "attachment" in key:
                        print(f"âš ï¸ å‘ç°ç–‘ä¼¼é™„ä»¶å­—æ®µ '{key}' ä½†æœªè¢«è¯†åˆ«ä¸ºæ–‡ä»¶å¯¹è±¡ (Type: {type(value)})")
            
            payload = CloudmailinPayload(
                plain=str(plain) if plain else None,
                html=str(html) if html else None,
                subject=str(subject),
                attachments=attachments_list
            )
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Form parsing error: {e}")

    # 2. æ·»åŠ åˆ°åå°ä»»åŠ¡
    background_tasks.add_task(process_email_task, payload)
    
    # 3. ç«‹å³è¿”å›å“åº”
    return {"status": "received", "message": "Processing started in background"}

class AnalyzeRequest(BaseModel):
    ticker: str

@app.post("/analyze")
async def api_analyze(request: AnalyzeRequest):
    """Web API: åˆ†æè‚¡ç¥¨æ¥å£"""
    print(f"ğŸŒ æ”¶åˆ° Web API åˆ†æè¯·æ±‚: {request.ticker}")
    
    loop = asyncio.get_running_loop()
    # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥çš„åˆ†ææµç¨‹ï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
    pdf_buffer, report, oi_chart_url = await loop.run_in_executor(
        None, 
        lambda: StockAnalyzer.run_full_analysis_pipeline(request.ticker)
    )
    
    if not report:
        raise HTTPException(status_code=404, detail="Analysis failed or ticker not found")

    # ä¸Šä¼  PDF åˆ° Supabase (å¦‚æœé…ç½®äº†)
    pdf_url = None
    if pdf_buffer and supabase:
        pdf_filename = f"{request.ticker}_{int(time.time())}.pdf"
        pdf_url = await loop.run_in_executor(None, lambda: StockAnalyzer.upload_file_to_supabase(pdf_filename, pdf_buffer, "application/pdf"))

    return {"status": "success", "ticker": request.ticker, "report": report, "pdf_url": pdf_url, "oi_chart_url": oi_chart_url}

@app.get("/")
def health_check():
    return {"status": "ok", "bot_status": "logged_in" if bot.is_ready() else "connecting"}

# ================= æ ¸å¿ƒé€»è¾‘æ¨¡å— (ä¿æŒä¸å˜) =================
class StockAnalyzer:
    @staticmethod
    def run_full_analysis_pipeline(ticker):
        """æ‰§è¡Œå®Œæ•´çš„åˆ†ææµç¨‹ (åŒæ­¥æ–¹æ³•ï¼Œä¾› Web Service è°ƒç”¨)"""
        try:
            ticker = ticker.upper()
            # Aè‚¡åç¼€å¤„ç†
            if ticker.isdigit() and len(ticker) == 6:
                if ticker.startswith('6'): ticker = f"{ticker}.SS" # ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€
                elif ticker.startswith(('0', '3')): ticker = f"{ticker}.SZ" # æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€
                elif ticker.startswith(('4', '8')): ticker = f"{ticker}.BJ" # åŒ—äº¬è¯åˆ¸äº¤æ˜“æ‰€

            # 1. è·å–æ•°æ®
            df, fund, news, macro_data = StockAnalyzer.get_data(ticker)
            if df is None: return None, None, None

            # 2. è®¡ç®—æŒ‡æ ‡
            df_tech = StockAnalyzer.calculate_indicators(df)
            latest = df_tech.iloc[-1]
            price_change = 0
            if len(df) >= 2:
                price_change = (df['Close'].iloc[-1] - df['Close'].iloc[-2]) / df['Close'].iloc[-2]

            # 3. å¤–éƒ¨æ•°æ®è·å–
            web_results = StockAnalyzer.get_web_search(ticker)
            stock_obj = yf.Ticker(ticker)
            gex_data = StockAnalyzer.get_gamma_exposure(stock_obj, fund['price'])
            flow_data = StockAnalyzer.get_option_flow(stock_obj, fund['price'])
            oi_chart_buffer = StockAnalyzer.get_option_open_interest_chart(stock_obj, fund['price'])
            
            # ä¸Šä¼  OI å›¾è¡¨
            oi_chart_url = None
            if oi_chart_buffer and supabase:
                oi_chart_filename = f"{ticker}_oi_chart_{int(time.time())}.png"
                oi_chart_url = StockAnalyzer.upload_file_to_supabase(oi_chart_filename, oi_chart_buffer, "image/png")

            # 4. AI ç”Ÿæˆ
            report = StockAnalyzer._generate_ai_report_sync(ticker, fund, df_tech, news, web_results, gex_data, flow_data, macro_data)

            # 5. PDF ç”Ÿæˆ
            pdf_buffer = StockAnalyzer.create_pdf_report(ticker, report, fund, latest, price_change, oi_chart_buffer)
            return pdf_buffer, report, oi_chart_url
        except Exception as e:
            print(f"Pipeline Error: {e}")
            return None, None, None

    @staticmethod
    def upload_file_to_supabase(filename: str, buffer: io.BytesIO, content_type: str) -> Optional[str]:
        """é€šç”¨æ–‡ä»¶ä¸Šä¼ åˆ° Supabase Storage å¹¶è¿”å›å…¬å¼€é“¾æ¥"""
        if not supabase:
            print("Supabase not configured, skipping upload.")
            return None
        try:
            path = f"{filename}"
            # ä½¿ç”¨ getvalue() æ¥è·å–å…¨éƒ¨å†…å®¹ï¼Œé¿å…ç§»åŠ¨ buffer çš„æŒ‡é’ˆ
            supabase.storage.from_(SUPABASE_BUCKET).upload(
                file=buffer.getvalue(),
                path=path,
                file_options={"content-type": content_type}
            )
            return supabase.storage.from_(SUPABASE_BUCKET).get_public_url(path)
        except Exception as e:
            print(f"Supabase upload error for {filename}: {e}")
            return None

    @staticmethod
    def get_data(ticker_symbol):
        """è·å–å†å²æ•°æ®å’Œæ›´å…¨é¢çš„åŸºæœ¬é¢ä¿¡æ¯"""
        try:
            stock = yf.Ticker(ticker_symbol)
            df = stock.history(period="1y")
            
            if df.empty:
                return None, None, None, None

            info = stock.info
            fundamentals = {
                "name": info.get('longName', ticker_symbol),
                "sector": info.get('sector', 'Unknown'),
                "price": info.get('currentPrice', df['Close'].iloc[-1]),
                "currency": info.get('currency', 'USD'),
                "market_cap": info.get('marketCap', 'N/A'),
                "pe": info.get('trailingPE', 'N/A'),
                "pb": info.get('priceToBook', 'N/A'),
                "eps": info.get('trailingEps', 'N/A'),
                "roe": info.get('returnOnEquity', 'N/A'),
                "debt_to_equity": info.get('debtToEquity', 'N/A'),
                "forward_pe": info.get('forwardPE', 'N/A'),
                "beta": info.get('beta', 'N/A'),
                "peg_ratio": info.get('pegRatio', 'N/A'),
                "profit_margins": info.get('profitMargins', 'N/A'),
                "short_percent": info.get('shortPercentOfFloat', 'N/A'),
                "business_summary": info.get('longBusinessSummary', 'æš‚æ— è¯¦ç»†ä¸šåŠ¡æè¿°'),
                "turnover_rate": "N/A"
            }
            
            # === è®¡ç®—æ¢æ‰‹ç‡ (Turnover Rate) ===
            # ä¼˜å…ˆä½¿ç”¨ floatShares (æµé€šè‚¡), å…¶æ¬¡ä½¿ç”¨ sharesOutstanding (æ€»è‚¡æœ¬)
            shares_base = info.get('floatShares') or info.get('sharesOutstanding')
            avg_vol_10d = info.get('averageVolume10days') or info.get('averageVolume')
            if shares_base and avg_vol_10d:
                fundamentals['turnover_rate'] = f"{(avg_vol_10d / shares_base):.2%}"

            # === æ–°å¢: è´¢åŠ¡æŠ¥è¡¨æ•°æ® (10-Q/10-K) ===
            financials_data = {}
            try:
                # è·å–å­£åº¦æŠ¥è¡¨
                q_income = stock.quarterly_financials
                q_balance = stock.quarterly_balance_sheet
                q_cashflow = stock.quarterly_cashflow

                if not q_income.empty:
                    latest_q = q_income.iloc[:, 0] # æœ€è¿‘ä¸€ä¸ªå­£åº¦
                    financials_data['date'] = str(latest_q.name).split(' ')[0]
                    financials_data['revenue'] = latest_q.get('Total Revenue', 'N/A')
                    financials_data['net_income'] = latest_q.get('Net Income', 'N/A')
                    financials_data['gross_profit'] = latest_q.get('Gross Profit', 'N/A')
                
                if not q_balance.empty:
                    latest_b = q_balance.iloc[:, 0]
                    financials_data['total_cash'] = latest_b.get('Cash And Cash Equivalents', 'N/A')
                    financials_data['total_debt'] = latest_b.get('Total Debt', 'N/A')
                
                if not q_cashflow.empty:
                    latest_c = q_cashflow.iloc[:, 0]
                    financials_data['op_cashflow'] = latest_c.get('Operating Cash Flow', 'N/A')
            except Exception as e:
                print(f"Financials Error: {e}")
            
            fundamentals['financials'] = financials_data

            # === æ–°å¢: åˆ†æå¸ˆæ•°æ® ===
            analyst_data = {
                'target_mean': info.get('targetMeanPrice', 'N/A'),
                'target_high': info.get('targetHighPrice', 'N/A'),
                'target_low': info.get('targetLowPrice', 'N/A'),
                'recommendation': info.get('recommendationKey', 'N/A'),
                'num_analysts': info.get('numberOfAnalystOpinions', 'N/A'),
                'recent_ratings': []
            }
            try:
                upgrades = stock.upgrades_downgrades
                if upgrades is not None and not upgrades.empty:
                    latest_upgrades = upgrades.sort_index(ascending=False).head(3)
                    for index, row in latest_upgrades.iterrows():
                        analyst_data['recent_ratings'].append(f"{str(index).split(' ')[0]}: {row['Firm']} -> {row['ToGrade']}")
            except Exception: pass
            fundamentals['analyst'] = analyst_data

            # === æ–°å¢: å…³é”®äº‹ä»¶æ—¥å† (Earnings & Events) ===
            try:
                cal = stock.calendar
                # yfinance calendar å¯èƒ½æ˜¯ dict æˆ– DataFrame
                if isinstance(cal, dict) and 'Earnings Date' in cal:
                    dates = cal['Earnings Date']
                    if dates:
                        next_date = dates[0] # é€šå¸¸æ˜¯æœ€è¿‘çš„ä¸€ä¸ª
                        fundamentals['next_earnings'] = str(next_date)
                        # è®¡ç®—å¤©æ•°
                        today = datetime.date.today()
                        if isinstance(next_date, datetime.datetime):
                            next_date = next_date.date()
                        fundamentals['days_to_earnings'] = (next_date - today).days
                else:
                    fundamentals['next_earnings'] = 'N/A'
                    fundamentals['days_to_earnings'] = 'N/A'
            except Exception:
                fundamentals['next_earnings'] = 'N/A'
                fundamentals['days_to_earnings'] = 'N/A'

            # === è·å–æœŸæƒæ•°æ® (Put/Call Ratio) ===
            try:
                exps = stock.options
                if exps:
                    # è·å–æœ€è¿‘çš„ä¸€ä¸ªåˆ°æœŸæ—¥
                    nearest_exp = exps[0]
                    opt = stock.option_chain(nearest_exp)
                    
                    # è®¡ç®—æ€»æˆäº¤é‡å’ŒæŒä»“é‡
                    c_vol = opt.calls['volume'].sum() if not opt.calls.empty else 0
                    p_vol = opt.puts['volume'].sum() if not opt.puts.empty else 0
                    c_oi = opt.calls['openInterest'].sum() if not opt.calls.empty else 0
                    p_oi = opt.puts['openInterest'].sum() if not opt.puts.empty else 0

                    fundamentals['pc_ratio_vol'] = round(p_vol / c_vol, 2) if c_vol > 0 else 'N/A'
                    fundamentals['pc_ratio_oi'] = round(p_oi / c_oi, 2) if c_oi > 0 else 'N/A'
                    fundamentals['options_expiry'] = nearest_exp
                else:
                    raise ValueError("No options")
            except Exception:
                fundamentals['pc_ratio_vol'] = 'N/A'
                fundamentals['pc_ratio_oi'] = 'N/A'
                fundamentals['options_expiry'] = 'N/A'
            
            news = stock.news
            
            # === è·å–å®è§‚å¸‚åœºæ•°æ® (Macro Data) ===
            macro_data = {}
            try:
                market_symbol = "^GSPC" # é»˜è®¤æ ‡æ™®500
                vix_symbol = "^VIX"
                
                if ticker_symbol.endswith(('.SS', '.SZ', '.BJ')):
                    market_symbol = "000001.SS" # ä¸Šè¯æŒ‡æ•°
                    vix_symbol = None # Aè‚¡æš‚ä¸è·å–VIX (æˆ–ä½¿ç”¨ 510050 ç­‰æ›¿ä»£ï¼Œæ­¤å¤„ç®€åŒ–)
                
                market_ticker = yf.Ticker(market_symbol)
                market_hist = market_ticker.history(period="5d")
                if not market_hist.empty:
                    macro_data['market_index'] = market_symbol
                    macro_data['market_price'] = market_hist['Close'].iloc[-1]
                    macro_data['market_change'] = (market_hist['Close'].iloc[-1] - market_hist['Close'].iloc[-2]) / market_hist['Close'].iloc[-2]
                
                if vix_symbol:
                    vix_ticker = yf.Ticker(vix_symbol)
                    vix_hist = vix_ticker.history(period="5d")
                    if not vix_hist.empty:
                        macro_data['vix'] = vix_hist['Close'].iloc[-1]
                        macro_data['vix_change'] = (vix_hist['Close'].iloc[-1] - vix_hist['Close'].iloc[-2]) / vix_hist['Close'].iloc[-2]
            except Exception as e:
                print(f"Macro Data Error: {e}")

            return df, fundamentals, news, macro_data
        except Exception as e:
            print(f"Data Error: {e}")
            return None, None, None, None

    @staticmethod
    def calculate_indicators(df):
        """è®¡ç®—æ›´å¤šæŠ€æœ¯å’Œé‡åŒ–æŒ‡æ ‡"""
        df = df.copy()
        
        # 1. ç§»åŠ¨å¹³å‡çº¿ (SMA)
        df['SMA_50'] = df['Close'].rolling(window=50).mean()
        df['SMA_200'] = df['Close'].rolling(window=200).mean()
        
        # 2. RSI (ç›¸å¯¹å¼ºå¼±æŒ‡æ•°)
        delta = df['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['RSI'] = 100 - (100 / (1 + rs))
        
        # 3. å¸ƒæ—å¸¦
        df['BB_Middle'] = df['Close'].rolling(window=20).mean()
        df['BB_Std'] = df['Close'].rolling(window=20).std()
        df['BB_Upper'] = df['BB_Middle'] + (2 * df['BB_Std'])
        df['BB_Lower'] = df['BB_Middle'] - (2 * df['BB_Std'])
        
        # 4. MACD
        exp1 = df['Close'].ewm(span=12, adjust=False).mean()
        exp2 = df['Close'].ewm(span=26, adjust=False).mean()
        df['MACD'] = exp1 - exp2
        df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()

        # 5. KDJ (éšæœºæŒ‡æ ‡ - Aè‚¡å¸¸ç”¨)
        # RSV = (Close - Low_9) / (High_9 - Low_9) * 100
        low_list = df['Low'].rolling(window=9, min_periods=9).min()
        high_list = df['High'].rolling(window=9, min_periods=9).max()
        rsv = (df['Close'] - low_list) / (high_list - low_list) * 100
        df['K'] = rsv.ewm(com=2, adjust=False).mean() # com=2 ç­‰åŒäº alpha=1/3
        df['D'] = df['K'].ewm(com=2, adjust=False).mean()
        df['J'] = 3 * df['K'] - 2 * df['D']

        # 6. ATR (å¹³å‡çœŸå®æ³¢å¹… - æ³¢åŠ¨ç‡æ›¿ä»£æŒ‡æ ‡)
        high_low = df['High'] - df['Low']
        high_close = (df['High'] - df['Close'].shift()).abs()
        low_close = (df['Low'] - df['Close'].shift()).abs()
        ranges = pd.concat([high_low, high_close, low_close], axis=1)
        true_range = ranges.max(axis=1)
        df['ATR'] = true_range.rolling(window=14).mean()

        # 5. æ³¢åŠ¨ç‡ (30æ—¥å†å²æ³¢åŠ¨ç‡)
        df['Log_Ret'] = df['Close'].apply(lambda x: np.log(x)).diff()
        df['Volatility'] = df['Log_Ret'].rolling(window=30).std() * np.sqrt(252) # å¹´åŒ–

        return df

    @staticmethod
    def get_web_search(ticker):
        """ä½¿ç”¨ DuckDuckGo æœç´¢æœ€æ–°çš„å¸‚åœºæ–°é—»ã€äº‹ä»¶ã€ç®¡ç†å±‚æŒ‡å¼•ä»¥åŠç¤¾äº¤åª’ä½“æƒ…ç»ª"""
        results = []
        try:
            is_ashare = ticker.endswith(('.SS', '.SZ', '.BJ'))
            with DDGS() as ddgs:
                # 1. æ ¸å¿ƒå‚¬åŒ–å‰‚ä¸æœªæ¥äº‹ä»¶ (Event-Driven Focus)
                query_event = f"{ticker} stock upcoming catalyst events earnings date fda approval product launch"
                if is_ashare:
                    query_event = f"{ticker} è‚¡ç¥¨ é‡å¤§åˆ©å¥½ ä¸šç»©é¢„å‘Š èµ„äº§é‡ç»„ æ”¿ç­–é©±åŠ¨"
                results.extend(list(ddgs.text(query_event, max_results=3)))

                # 2. éšå«æ³¢åŠ¨ç‡ä¸æœŸæƒå¼‚åŠ¨ (Market Pricing of Events)
                query_iv = f"{ticker} stock implied volatility rank option flow unusual activity"
                if is_ashare:
                    # Aè‚¡æ›¿ä»£æœç´¢: åŒ—å‘èµ„é‡‘ã€é¾™è™æ¦œã€ä¸»åŠ›èµ„é‡‘
                    query_iv = f"{ticker} åŒ—å‘èµ„é‡‘æµå‘ é¾™è™æ¦œæ•°æ® ä¸»åŠ›èµ„é‡‘ èèµ„èåˆ¸"
                results.extend(list(ddgs.text(query_iv, max_results=2)))
                
                # 3. 10-Q/10-K ç®¡ç†å±‚æŒ‡å¼•
                query_guidance = f"{ticker} stock earnings guidance management discussion 10-Q highlights"
                results.extend(list(ddgs.text(query_guidance, max_results=2)))
                
                # 4. ç¤¾äº¤åª’ä½“æƒ…ç»ª - åˆ†å¼€æœç´¢ä»¥æé«˜è¦†ç›–ç‡
                # 4.1 Reddit æ·±åº¦è®¨è®º (r/stocks, r/investing, r/wallstreetbets)
                query_reddit = f"site:reddit.com {ticker} stock due diligence discussion analysis"
                reddit_results = list(ddgs.text(query_reddit, max_results=3))
                for r in reddit_results:
                    r['title'] = f"[Reddit] {r['title']}"
                results.extend(reddit_results)

                # 4.2 Stocktwits æƒ…ç»ª (æ•£æˆ·å¤§æœ¬è¥)
                query_st = f"site:stocktwits.com {ticker} sentiment bullish bearish"
                st_results = list(ddgs.text(query_st, max_results=2))
                for r in st_results:
                    r['title'] = f"[Stocktwits] {r['title']}"
                results.extend(st_results)

                # 5. æ‰€å±æ¿å—è¶‹åŠ¿ (Sector Trends)
                query_sector = f"{ticker} sector industry trends performance outlook"
                results.extend(list(ddgs.text(query_sector, max_results=2)))

                return results
        except Exception as e:
            print(f"Web Search Error: {e}")
            return results

    @staticmethod
    def get_risk_free_rate():
        """è·å–å½“å‰æ— é£é™©åˆ©ç‡ (åŸºäº 10å¹´æœŸç¾å€ºæ”¶ç›Šç‡ ^TNX)"""
        try:
            tnx = yf.Ticker("^TNX")
            hist = tnx.history(period="5d")
            if not hist.empty:
                return hist['Close'].iloc[-1] / 100.0
        except Exception as e:
            print(f"Risk-Free Rate Error: {e}")
        return 0.045 # é»˜è®¤ 4.5%

    @staticmethod
    def black_scholes_gamma(S, K, T, r, sigma):
        """è®¡ç®— Black-Scholes Gamma"""
        try:
            if T <= 0 or sigma <= 0:
                return 0
            d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))
            gamma = norm.pdf(d1) / (S * sigma * np.sqrt(T))
            return gamma
        except:
            return 0

    @staticmethod
    def get_gamma_exposure(stock, current_price):
        """è®¡ç®— Gamma Exposure (GEX) å’Œå…³é”®æŒ¤å‹ä½ç½®"""
        try:
            exps = stock.options
            if not exps:
                return None
            
            # ä½¿ç”¨æœ€è¿‘çš„åˆ°æœŸæ—¥ (Gamma é£é™©æœ€å¤§)
            expiry_date_str = exps[0]
            expiry_date = datetime.datetime.strptime(expiry_date_str, "%Y-%m-%d").date()
            today = datetime.date.today()
            T = (expiry_date - today).days / 365.0
            if T <= 1e-5: T = 1/365.0 # é˜²æ­¢é™¤ä»¥é›¶

            opt = stock.option_chain(expiry_date_str)
            calls = opt.calls.copy()
            puts = opt.puts.copy()
            
            r = StockAnalyzer.get_risk_free_rate()
            
            # è®¡ç®— Gamma
            calls['gamma'] = calls.apply(lambda x: StockAnalyzer.black_scholes_gamma(current_price, x['strike'], T, r, x['impliedVolatility']), axis=1)
            puts['gamma'] = puts.apply(lambda x: StockAnalyzer.black_scholes_gamma(current_price, x['strike'], T, r, x['impliedVolatility']), axis=1)

            # è®¡ç®— GEX (åä¹‰ä»·å€¼) = Gamma * OI * 100 * Price
            # Call GEX é€šå¸¸è§†ä¸ºæ­£å‘ (Dealer Short Call -> Long Stock to hedge)
            # Put GEX é€šå¸¸è§†ä¸ºè´Ÿå‘ (Dealer Short Put -> Short Stock to hedge)
            calls['gex'] = calls['gamma'] * calls['openInterest'] * 100 * current_price
            puts['gex'] = puts['gamma'] * puts['openInterest'] * 100 * current_price * -1

            # å¯»æ‰¾å…³é”®å¢™ (Walls)
            call_wall = calls.loc[calls['gex'].idxmax()]['strike'] if not calls.empty else 0
            put_wall = puts.loc[puts['gex'].abs().idxmax()]['strike'] if not puts.empty else 0
            net_gex = calls['gex'].sum() + puts['gex'].sum()

            return {
                "expiry": expiry_date_str,
                "call_wall": call_wall,
                "put_wall": put_wall,
                "net_gex": net_gex
            }
        except Exception as e:
            print(f"GEX Error: {e}")
            return None

    @staticmethod
    def get_option_flow(stock, current_price):
        """åˆ†ææœŸæƒèµ„é‡‘æµï¼Œå¯»æ‰¾å¼‚å¸¸å¤§å•å’Œèªæ˜é’±å¸ƒå±€ (Volume > Open Interest)"""
        try:
            exps = stock.options
            if not exps:
                return []
            
            flow_data = []
            today = datetime.date.today()
            cutoff_date = today + datetime.timedelta(days=180)

            # æ‰«ææœªæ¥åŠå¹´å†…çš„åˆ°æœŸæ—¥
            for date in exps:
                try:
                    if datetime.datetime.strptime(date, "%Y-%m-%d").date() > cutoff_date:
                        continue
                    opt = stock.option_chain(date)
                    
                    # ç­›é€‰é€»è¾‘: æˆäº¤é‡ > 500 ä¸” æˆäº¤é‡ > æŒä»“é‡ * 1.1 (ç–‘ä¼¼ä¸»åŠ›ä¸»åŠ¨å¼€ä»“)
                    # Calls
                    calls = opt.calls
                    if not calls.empty:
                        active_calls = calls[
                            (calls['volume'] > 500) & 
                            (calls['volume'] > calls['openInterest'] * 1.1)
                        ].copy()
                        for _, row in active_calls.iterrows():
                            flow_data.append({
                                'type': 'CALL ğŸ‚',
                                'expiry': date,
                                'strike': row['strike'],
                                'volume': int(row['volume']),
                                'oi': int(row['openInterest']),
                                'ratio': round(row['volume'] / (row['openInterest'] if row['openInterest'] > 0 else 1), 1)
                            })

                    # Puts
                    puts = opt.puts
                    if not puts.empty:
                        active_puts = puts[
                            (puts['volume'] > 500) & 
                            (puts['volume'] > puts['openInterest'] * 1.1)
                        ].copy()
                        for _, row in active_puts.iterrows():
                            flow_data.append({
                                'type': 'PUT ğŸ»',
                                'expiry': date,
                                'strike': row['strike'],
                                'volume': int(row['volume']),
                                'oi': int(row['openInterest']),
                                'ratio': round(row['volume'] / (row['openInterest'] if row['openInterest'] > 0 else 1), 1)
                            })
                except Exception: continue
            
            # æŒ‰æˆäº¤é‡é™åºæ’åºï¼Œå–å‰ 5 å¤§å¼‚åŠ¨
            flow_data.sort(key=lambda x: x['volume'], reverse=True)
            return flow_data[:5]
        except Exception as e:
            print(f"Flow Error: {e}")
            return []

    @staticmethod
    def get_option_open_interest_chart(stock, current_price):
        """ç”ŸæˆæœŸæƒæŒä»“é‡ (Open Interest) åˆ†å¸ƒå›¾"""
        try:
            exps = stock.options
            if not exps: return None
            
            # ä½¿ç”¨æœ€è¿‘çš„åˆ°æœŸæ—¥
            expiry = exps[0]
            opt = stock.option_chain(expiry)
            
            calls = opt.calls
            puts = opt.puts
            
            if calls.empty and puts.empty: return None
            
            # ç­›é€‰å½“å‰ä»·æ ¼é™„è¿‘ +/- 15% çš„è¡Œæƒä»·ï¼Œé¿å…å›¾è¡¨è¿‡å®½
            lower_bound = current_price * 0.85
            upper_bound = current_price * 1.15
            
            calls = calls[(calls['strike'] >= lower_bound) & (calls['strike'] <= upper_bound)]
            puts = puts[(puts['strike'] >= lower_bound) & (puts['strike'] <= upper_bound)]
            
            if calls.empty and puts.empty: return None

            # ç»˜å›¾
            plt.style.use('ggplot')
            fig, ax = plt.subplots(figsize=(8, 3))
            
            # æå–æ•°æ®
            # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬åªç”»å‡ºæœ‰æ•°æ®çš„ Strike
            all_strikes = sorted(list(set(calls['strike'].tolist() + puts['strike'].tolist())))
            
            call_oi = [calls[calls['strike'] == k]['openInterest'].sum() for k in all_strikes]
            put_oi = [puts[puts['strike'] == k]['openInterest'].sum() for k in all_strikes]
            
            indices = np.arange(len(all_strikes))
            width = 0.35
            
            ax.bar(indices - width/2, call_oi, width, label='Call OI', color='#2ca02c', alpha=0.8)
            ax.bar(indices + width/2, put_oi, width, label='Put OI', color='#d62728', alpha=0.8)
            
            ax.set_xticks(indices)
            ax.set_xticklabels([str(int(s)) for s in all_strikes], rotation=45, fontsize=7)
            ax.set_title(f'Open Interest Distribution (Expiry: {expiry})', fontsize=10)
            ax.legend(fontsize=8, loc='upper right')
            ax.grid(True, alpha=0.3)
            
            # æ ‡è®°å½“å‰ä»·æ ¼
            curr_idx = np.interp(current_price, all_strikes, indices)
            ax.axvline(x=curr_idx, color='blue', linestyle='--', alpha=0.6, label='Current Price')
            
            plt.tight_layout()
            
            buf = io.BytesIO()
            plt.savefig(buf, format='png', dpi=100)
            buf.seek(0)
            plt.close(fig)
            return buf
        except Exception as e:
            print(f"Chart Error: {e}")
            return None

    @staticmethod
    def create_pdf_report(ticker, report_text, fund_data, tech_latest, price_change, oi_chart_buffer):
        """ç”Ÿæˆ PDF æŠ¥å‘Š"""
        try:
            buffer = io.BytesIO()
            # è°ƒæ•´é¡µè¾¹è·ï¼Œå¢åŠ å†…å®¹å®¹çº³ç©ºé—´
            doc = SimpleDocTemplate(buffer, pagesize=letter, rightMargin=40, leftMargin=40, topMargin=40, bottomMargin=40)
            styles = getSampleStyleSheet()
            
            # æ³¨å†Œä¸­æ–‡å­—ä½“ (STSong-Light æ˜¯ Adobe é¢„å®šä¹‰çš„ç®€ä½“ä¸­æ–‡å­—ä½“ï¼Œæ— éœ€é¢å¤–å­—ä½“æ–‡ä»¶)
            pdfmetrics.registerFont(UnicodeCIDFont('STSong-Light'))
            
            # === è‡ªå®šä¹‰æ ·å¼ä¼˜åŒ– ===
            title_style = ParagraphStyle(
                'CustomTitle', parent=styles['Title'], fontName='STSong-Light', fontSize=24, leading=28, spaceAfter=10, alignment=1, textColor=colors.HexColor("#1a73e8"),
                keepWithNext=True # ç¡®ä¿æ ‡é¢˜ä¸ä¸åç»­å†…å®¹åˆ†é¡µ
            )
            heading_style = ParagraphStyle(
                'CustomHeading', parent=styles['Heading2'], fontName='STSong-Light', fontSize=15, leading=18, spaceBefore=15, spaceAfter=8, textColor=colors.HexColor("#202124"),
                keepWithNext=True # ç¡®ä¿æ ‡é¢˜ä¸ä¸åç»­å†…å®¹åˆ†é¡µ
            )
            normal_style = ParagraphStyle(
                'CustomNormal', parent=styles['Normal'], fontName='STSong-Light', fontSize=10.5, leading=15, spaceAfter=6, textColor=colors.HexColor("#3c4043")
            )
            bullet_style = ParagraphStyle(
                'CustomBullet', parent=normal_style, leftIndent=15, firstLineIndent=0, spaceAfter=4, bulletFontName='STSong-Light'
            )
            sub_bullet_style = ParagraphStyle(
                'CustomSubBullet', parent=normal_style, leftIndent=35, firstLineIndent=0, spaceAfter=4, bulletFontName='STSong-Light'
            )
            
            story = []
            
            # 1. æŠ¥å‘Šæ ‡é¢˜
            story.append(Paragraph(f"{ticker} æ·±åº¦æŠ•èµ„åˆ†ææŠ¥å‘Š", title_style))
            story.append(Spacer(1, 15))
            
            # 2. é¡¶éƒ¨ä»ªè¡¨ç›˜ (Dashboard)
            def fmt_num(n):
                if isinstance(n, (int, float)):
                    if n > 1e12: return f"{n/1e12:.2f}T"
                    if n > 1e9: return f"{n/1e9:.2f}B"
                    return f"{n:,.2f}"
                return str(n)
            
            # æ¶¨è·Œå¹…é¢œè‰²
            change_color = colors.green if price_change >= 0 else colors.red
            change_str = f"{price_change:+.2%}"

            # ä»ªè¡¨ç›˜æ•°æ®
            dash_data = [
                [f"{ticker}", f"{fund_data.get('price', 'N/A')}", change_str, fmt_num(fund_data.get('market_cap', 'N/A'))],
                ["TICKER", "PRICE", "24H CHANGE", "MARKET CAP"]
            ]
            dash_table = Table(dash_data, colWidths=[120, 120, 120, 120])
            dash_table.setStyle(TableStyle([
                ('FONTNAME', (0, 0), (-1, -1), 'Helvetica'),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTSIZE', (0, 0), (-1, 0), 16), # ç¬¬ä¸€è¡Œå¤§å­—
                ('FONTSIZE', (0, 1), (-1, 1), 8),  # ç¬¬äºŒè¡Œæ ‡ç­¾å°å­—
                ('TEXTCOLOR', (0, 1), (-1, 1), colors.grey),
                ('TEXTCOLOR', (2, 0), (2, 0), change_color), # æ¶¨è·Œå¹…é¢œè‰²
                ('BOTTOMPADDING', (0, 0), (-1, 0), 6),
                ('TOPPADDING', (0, 1), (-1, 1), 4),
                ('BOX', (0, 0), (-1, -1), 1, colors.HexColor("#e0e0e0")),
                ('BACKGROUND', (0, 0), (-1, -1), colors.HexColor("#f8f9fa")),
            ]))
            story.append(dash_table)
            story.append(Spacer(1, 15))

            # 3. å…³é”®æŒ‡æ ‡çº¢ç»¿ç¯ (Key Indicators)
            # é€»è¾‘: RSI < 30 (è¶…å–/ç»¿), > 70 (è¶…ä¹°/çº¢); P/E ä»…å±•ç¤º
            rsi_val = tech_latest.get('RSI', 50)
            rsi_color = colors.green if rsi_val < 30 else (colors.red if rsi_val > 70 else colors.black)
            
            ind_data = [
                ['P/E (TTM)', 'RSI (14)', 'Volatility', 'P/C Ratio'],
                [str(fund_data.get('pe', 'N/A')), f"{rsi_val:.2f}", f"{tech_latest.get('Volatility', 0):.2%}", str(fund_data.get('pc_ratio_vol', 'N/A'))]
            ]
            t = Table(ind_data, colWidths=[120, 120, 120, 120])
            t.setStyle(TableStyle([
                ('FONTNAME', (0, 0), (-1, -1), 'Helvetica'),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#e8f0fe")), # è¡¨å¤´èƒŒæ™¯
                ('TEXTCOLOR', (1, 1), (1, 1), rsi_color), # RSI é¢œè‰²
                ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor("#e0e0e0")),
            ]))
            story.append(t)
            story.append(Spacer(1, 20))

            # 4. æ’å…¥æœŸæƒ OI å›¾è¡¨
            if oi_chart_buffer:
                img = Image(oi_chart_buffer, width=480, height=180)
                story.append(img)
                # æ·»åŠ å›¾è¡¨è¯´æ˜
                oi_desc = "<b>å›¾è¡¨è¯´æ˜:</b> ç»¿è‰²=CallæŒä»“(æ½œåœ¨é˜»åŠ›), çº¢è‰²=PutæŒä»“(æ½œåœ¨æ”¯æ’‘), è“è‰²è™šçº¿=å½“å‰è‚¡ä»·. æœ€é«˜çš„æŸ±å­é€šå¸¸ä»£è¡¨å…³é”®çš„å¸‚åœºåšå¼ˆç‚¹ä½(Walls)."
                story.append(Paragraph(oi_desc, ParagraphStyle('OIDesc', parent=normal_style, fontSize=9, textColor=colors.grey, alignment=1, spaceBefore=5)))
                story.append(Spacer(1, 20))
            
            # 5. è§£æ Markdown æ–‡æœ¬å¹¶è½¬æ¢ä¸º PDF å…ƒç´ 
            def clean_text(text):
                # 1. æ›¿æ¢ä¼šå¯¼è‡´ä¹±ç çš„ç‰¹æ®Šç¬¦å· (Smart Quotes, Dashes, Bullets)
                replacements = {
                    '\u2014': '-',  # Em Dash (â€”) -> ç¯³
                    '\u2013': '-',  # En Dash (â€“)
                    '\u2018': "'",  # Left Single Quote (â€˜)
                    '\u2019': "'",  # Right Single Quote (â€™) -> ç¯³
                    '\u201c': '"',  # Left Double Quote (â€œ)
                    '\u201d': '"',  # Right Double Quote (â€)
                    '\u2022': '-',  # Bullet (â€¢)
                    '\u25e6': '-',  # White Bullet (â—¦)
                    '\u27a2': '->', # Arrow (â¢) -> ç¸´
                    '\u2026': '...', # Ellipsis (â€¦)
                }
                for k, v in replacements.items():
                    text = text.replace(k, v)
                
                # 2. ä»…ä¿ç•™å®‰å…¨å­—ç¬¦ (ASCII + ä¸­æ–‡ + å¸¸ç”¨æ ‡ç‚¹)
                # è¿‡æ»¤æ‰ Emoji å’Œå…¶ä»–ç”Ÿåƒ»ç¬¦å·
                return "".join(c for c in text if 
                               (0x20 <= ord(c) <= 0x7E) or  # ASCII
                               (0x4E00 <= ord(c) <= 0x9FFF) or # CJK Unified Ideographs
                               (0x3000 <= ord(c) <= 0x303F) or # CJK Punctuation
                               (0xFF00 <= ord(c) <= 0xFFEF) or # Fullwidth ASCII
                               c in '\n\r\t')

            def format_content(text):
                # 1. ä¸­è‹±æ–‡ä¹‹é—´å¢åŠ ç©ºæ ¼ (Pangu Spacing)
                text = re.sub(r'([\u4e00-\u9fa5])([A-Za-z0-9])', r'\1 \2', text)
                text = re.sub(r'([A-Za-z0-9])([\u4e00-\u9fa5])', r'\1 \2', text)
                
                # 2. å°† ASCII å­—ç¬¦ (è‹±æ–‡/æ•°å­—/æ ‡ç‚¹) åŒ…è£¹åœ¨ Helvetica å­—ä½“ä¸­ï¼Œè§£å†³ STSong-Light è‹±æ–‡æŒ¤å‹é—®é¢˜
                # æ’é™¤ * (ç”¨äºåŠ ç²—) å’Œ < > (ç”¨äºæ ‡ç­¾)
                def repl(match):
                    return f'<font name="Helvetica">{match.group(1)}</font>'
                text = re.sub(r'([A-Za-z0-9\.\,\%\$\-\+\:\/\=\(\)\?\!]+)', repl, text)
                
                # 3. å¤„ç†åŠ ç²— (**Text** -> <b>Text</b>)
                text = re.sub(r'\*\*(.*?)\*\*', r'<b>\1</b>', text)
                return text

            lines = report_text.split('\n')
            for line in lines:
                line = clean_text(line)
                # æ£€æµ‹ç¼©è¿› (ç”¨äºåˆ¤æ–­åµŒå¥—åˆ—è¡¨)
                is_indented = line.startswith('  ') or line.startswith('\t')
                
                line = line.strip()
                if not line: continue
                line = line.replace('```', '')
                
                if line.startswith('#'):
                    # æ ‡é¢˜å¤„ç†ï¼šä¼˜åŒ–ç¼–å·ä¸æ ‡é¢˜ä¹‹é—´çš„é—´è·
                    level = line.count('#')
                    text = line.lstrip('#').strip()
                    # ä½¿ç”¨ Regex åœ¨æ•°å­—ç¼–å·(å¦‚ "1.")åæ·»åŠ ä¸æ¢è¡Œç©ºæ ¼ï¼Œå¢åŠ é—´è·
                    # ä½¿ç”¨ \u00A0 é˜²æ­¢è¢« format_content ç ´å
                    text = re.sub(r'^(\d+\.)\s*', lambda m: f"{m.group(1)}\u00A0\u00A0", text)
                    
                    # æ ¼å¼åŒ–å†…å®¹
                    text = format_content(text)
                    
                    if level == 1:
                        story.append(Paragraph(text, title_style))
                        # === ä¼˜åŒ–: åœ¨ä¸€çº§æ ‡é¢˜ä¸‹æ·»åŠ åˆ†å‰²çº¿ ===
                        d = Drawing(512, 1) # å®½åº¦åŒ¹é…é¡µè¾¹è· (612 - 50 - 50 = 512)
                        d.add(Line(0, 0, 512, 0, strokeColor=colors.HexColor("#1a73e8"), strokeWidth=1))
                        d.keepWithNext = True # ç¡®ä¿åˆ†å‰²çº¿ç´§è´´ä¸‹ä¸€å…ƒç´ 
                        story.append(d)
                        s = Spacer(1, 8)
                        s.keepWithNext = True # ç¡®ä¿é—´éš”ç´§è´´ä¸‹ä¸€å…ƒç´  (æ­£æ–‡)
                        story.append(s)
                    else:
                        story.append(Paragraph(text, heading_style))
                        
                elif line.startswith('- ') or line.startswith('* '):
                    content = line[2:]
                    content = format_content(content)
                    # ç­–ç•¥éƒ¨åˆ†ä¼˜åŒ–ï¼šå¦‚æœæ˜¯é£æ§å‚æ•°ç›¸å…³çš„è¡Œï¼Œå¼ºåˆ¶ç¼©è¿›
                    # æ³¨æ„ï¼šcontent ç°åœ¨å¯èƒ½åŒ…å« <font> æ ‡ç­¾ï¼Œæ­£åˆ™éœ€è¦é€‚é…
                    is_strategy_param = re.search(r'(å…¥åœº|æ­¢ç›ˆ|æ­¢æŸ|ä»“ä½|Entry|TP|SL)', content)
                    
                    if is_indented or is_strategy_param:
                        story.append(Paragraph(f"  {content}", sub_bullet_style)) # ç§»é™¤ç‰¹æ®Šç¬¦å· â—¦
                    else:
                        story.append(Paragraph(f"-&nbsp; {content}", bullet_style)) # å°† â€¢ æ›¿æ¢ä¸ºå®‰å…¨çš„ -
                else:
                    line = format_content(line)
                    story.append(Paragraph(line, normal_style))
            
            # 4. æ·»åŠ æ–‡æœ«å…è´£å£°æ˜æ¿å—
            story.append(Spacer(1, 20))
            disclaimer = "<b>å…è´£å£°æ˜ (Disclaimer):</b> æœ¬æŠ¥å‘Šç”± AI ç³»ç»ŸåŸºäºå…¬å¼€æ•°æ®è‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›ä¿¡æ¯å‚è€ƒï¼Œä¸æ„æˆä»»ä½•æŠ•èµ„å»ºè®®ã€‚å¸‚åœºæœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚è¯·åŠ¡å¿…ç»“åˆç‹¬ç«‹æ€è€ƒä¸ä¸“ä¸šé¡¾é—®æ„è§è¿›è¡Œå†³ç­–ã€‚"
            story.append(Paragraph(disclaimer, ParagraphStyle('Disclaimer', parent=normal_style, fontSize=8, textColor=colors.grey, alignment=0)))

            # æ·»åŠ é¡µè„š
            def add_footer(canvas, doc):
                canvas.saveState()
                canvas.setFont('STSong-Light', 9)
                canvas.setFillColor(colors.grey)
                canvas.drawCentredString(letter[0]/2.0, 30, "Generated by DeepSeek AI Stock Bot | Not Financial Advice")
                canvas.restoreState()

            doc.build(story, onFirstPage=add_footer, onLaterPages=add_footer)
            buffer.seek(0)
            return buffer
        except Exception as e:
            print(f"PDF Generation Error: {e}")
            return None

    @staticmethod
    def _generate_ai_report_sync(ticker, fund, tech_data, news_data, web_search_data, gex_data, flow_data, macro_data):
        """ç”Ÿæˆ AI æŠ¥å‘Šå†…å®¹çš„åŒæ­¥æ ¸å¿ƒæ–¹æ³•"""
        latest = tech_data.iloc[-1]
        current_date = datetime.datetime.now().strftime("%Y-%m-%d")

        # Safely extract news headlines, skipping items that might not have a 'title' key.
        news_headlines = "\n".join([f"- {n['title']}" for n in news_data[:5] if 'title' in n])
        
        # æ ¼å¼åŒ–ç½‘ç»œæœç´¢ç»“æœ
        web_content = "\n".join([f"- [Web] {r['title']}: {r['body']}" for r in web_search_data])

        # æ ¼å¼åŒ– GEX æ•°æ®
        gex_info = "- æš‚æ— æœŸæƒ Gamma æ•°æ®"
        if gex_data:
            gex_info = f"""
            - åˆ°æœŸæ—¥: {gex_data['expiry']}
            - Net GEX (å‡€ä¼½é©¬æ•å£): ${gex_data['net_gex']:,.0f}
            - Call Wall (æœ€å¤§é˜»åŠ›/åšå¸‚å•†åšç©ºç‚¹): {gex_data['call_wall']}
            - Put Wall (æœ€å¤§æ”¯æ’‘/åšå¸‚å•†å›è¡¥ç‚¹): {gex_data['put_wall']} """

        # æ ¼å¼åŒ–èµ„é‡‘æµæ•°æ®
        flow_info = "- æš‚æ— æ˜¾è‘—æœŸæƒå¼‚åŠ¨"
        if flow_data:
            flow_info = "\n".join([f"- {f['type']} | åˆ°æœŸ: {f['expiry']} | è¡Œæƒ: {f['strike']} | Vol: {f['volume']} (OI: {f['oi']}, å€æ•°: {f['ratio']}x)" for f in flow_data])

        # æ ¼å¼åŒ–åˆ†æå¸ˆè¯„çº§
        analyst_ratings_str = "- æš‚æ— è¿‘æœŸè¯„çº§å˜åŠ¨"
        if fund['analyst']['recent_ratings']:
            analyst_ratings_str = "\n".join([f"  - {r}" for r in fund['analyst']['recent_ratings']])

        # æ ¼å¼åŒ–å®è§‚æ•°æ®
        market_price = macro_data.get('market_price')
        market_price_str = f"{market_price:.2f}" if isinstance(market_price, (int, float)) else "N/A"
        market_change = macro_data.get('market_change')
        market_change_str = f"{market_change:+.2%}" if isinstance(market_change, (int, float)) else "N/A"
        
        vix_val = macro_data.get('vix')
        vix_str = f"{vix_val:.2f}" if isinstance(vix_val, (int, float)) else "N/A"
        vix_change = macro_data.get('vix_change')
        vix_change_str = f"{vix_change:+.2%}" if isinstance(vix_change, (int, float)) else "N/A"

        # æ„å»ºæ›´å¼ºå¤§çš„æç¤ºè¯ (Prompt)
        prompt = f"""
            # Role
            ä½ æ˜¯ä¸€ä½æ‹¥æœ‰20å¹´æ·±åšèµ„å†çš„åå°”è¡—é‡åŒ–ä¸å®è§‚å¯¹å†²åŸºé‡‘é¦–å¸­æŠ•èµ„å®˜ (CIO)ã€‚ä½ æ“…é•¿å°†è‡ªä¸Šè€Œä¸‹çš„å®è§‚é€»è¾‘ï¼ˆTop-Downï¼‰ä¸è‡ªä¸‹è€Œä¸Šçš„é‡åŒ–å› å­ï¼ˆBottom-Upï¼‰ç›¸ç»“åˆï¼ŒæŒ–æ˜å¸‚åœºå°šæœªå®Œå…¨å®šä»·çš„â€œé¢„æœŸå·®â€ã€‚

            # Analysis Requirements
            è¯·åŸºäºä»¥ä¸‹æ•°æ®ï¼Œç”Ÿæˆä¸€ä»½é€»è¾‘ä¸¥å¯†ã€å…·å¤‡å®æˆ˜æŒ‡å¯¼æ„ä¹‰çš„åˆ†ææŠ¥å‘Šã€‚
            **è¯·ç›´æ¥å¼€å§‹æŠ¥å‘Šå†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•è‡ªæˆ‘ä»‹ç»æˆ–å¼€åœºç™½ã€‚**
            
            ç»“æ„è¦æ±‚å¦‚ä¸‹ï¼š

            ### 1.  æ ¸å¿ƒç»“è®ºä¸äº¤æ˜“é©±åŠ¨ (Executive Summary & Driver)
            - **äº¤æ˜“é©±åŠ¨ç±»å‹**: [åŸºæœ¬é¢é©±åŠ¨ / äº‹ä»¶é©±åŠ¨ / é‡åŒ–é©±åŠ¨ / æŠ€æœ¯é¢é©±åŠ¨] (è¯·æ ¹æ®åˆ†æåˆ¤å®šä¸»å¯¼å› ç´ )
            - **æŠ•èµ„è¯„çº§**: (å¼ºåŠ›ä¹°å…¥ / ä¹°å…¥ / å¢æŒ / ä¸­æ€§ / å‡æŒ / å–å‡º)
            - **æ“ä½œæ—¶é—´æ¡†æ¶**: (ä¾‹å¦‚: çŸ­çº¿æ³¢æ®µ / ä¸­æœŸè¶‹åŠ¿ / é•¿çº¿é…ç½®)
            - **AI ç½®ä¿¡åº¦**: (ä¾‹å¦‚: æé«˜ç½®ä¿¡åº¦ >90% / é«˜ç½®ä¿¡åº¦ 75-90% / ä¸­ç­‰ç½®ä¿¡åº¦ 60-75% / ä½ç½®ä¿¡åº¦ <60%)
            - **æ“ä½œè®¡åˆ’**:
              - å…¥åœºåŒºé—´ (Entry): [å…·ä½“ä»·æ ¼]
              - ç›®æ ‡æ­¢ç›ˆ (TP): [å…·ä½“ä»·æ ¼]
              - ç¡¬æ€§æ­¢æŸ (SL): [å…·ä½“ä»·æ ¼]
            - **æ ¸å¿ƒé€»è¾‘æ‘˜è¦**: ä¸€å¥è¯æ¦‚æ‹¬ä¸ºä½•åšæ­¤äº¤æ˜“ã€‚

            ### 2. ğŸ›ï¸ å®è§‚å™äº‹ä¸åŸºæœ¬é¢ (Macro & Fundamentals)
            - **å®è§‚ç¯å¢ƒ**: ç»“åˆå¤§ç›˜èµ°åŠ¿ ({macro_data.get('market_index', 'Market')}) å’Œ VIX ææ…ŒæŒ‡æ•°ï¼Œåˆ¤æ–­å½“å‰å¸‚åœºæ˜¯ Risk-On è¿˜æ˜¯ Risk-Offã€‚
            - **æ¿å—è¶‹åŠ¿**: åˆ†ææ‰€å±æ¿å— ({fund['sector']}) çš„æ•´ä½“è¡¨ç°ã€‚
            - **AI/FSD/å¢é•¿æ•…äº‹**: ç»“åˆä¸šåŠ¡æŒ‡å¼•å’Œè¡Œä¸šè¶‹åŠ¿ï¼Œåˆ†ææ ¸å¿ƒå¢é•¿é€»è¾‘ã€‚
            - **ä¼°å€¼é€»è¾‘**: P/E æ˜¯å¦åˆç†ï¼Ÿç»“åˆ PEG å’Œå†å²åˆ†ä½åˆ¤æ–­ã€‚

            ### 3. ğŸ”¬ å¾®è§‚ç­¹ç ä¸æœŸæƒåšå¼ˆ (Micro & Chips)
            - **Gamma Squeeze é£é™©**: åˆ†æ Call Wall/Put Wall ä½ç½®ï¼Œåˆ¤æ–­æ˜¯å¦å­˜åœ¨é€¼ç©ºæˆ–æ€è·ŒåŠ¨èƒ½ã€‚
            - **èµ„é‡‘æµå‘ (Smart Money)**: è§£è¯»æœŸæƒå¼‚åŠ¨ (Option Flow)ï¼Œä¸»åŠ›æ˜¯åœ¨å¸ƒå±€åå¼¹è¿˜æ˜¯å¯¹å†²é£é™©ï¼Ÿ
            - **äº¤æ˜“å‘˜æƒ…ç»ª**: ç»“åˆç¤¾äº¤åª’ä½“æƒ…ç»ªï¼Œåˆ¤æ–­å¸‚åœºæ˜¯å¦è¿‡çƒ­æˆ–ææ…Œã€‚

            ### 4. ğŸ“ˆ æŠ€æœ¯é¢å…±æŒ¯ (Technicals)
            - **å…³é”®å‡çº¿**: 50D/200D SMA çš„æ”¯æ’‘ä¸é˜»åŠ›ã€‚
            - **æŒ‡æ ‡ä¿¡å·**: RSI æ˜¯å¦è¶…ä¹°/è¶…å–ï¼ŸMACD æ˜¯å¦èƒŒç¦»ï¼Ÿ
            
            è¯·ä½¿ç”¨ä¸“ä¸šã€ç®€æ´ã€å¯Œæœ‰æ´å¯ŸåŠ›çš„è¯­è¨€è¾“å‡ºã€‚

            # Input Data Panel
            - **å½“å‰åˆ†ææ—¥æœŸ**: {current_date}

            ## 0. å®è§‚å¸‚åœºç¯å¢ƒ (Macro Context)
            - å¤§ç›˜æŒ‡æ•° ({macro_data.get('market_index', 'N/A')}): {market_price_str} (Change: {market_change_str})
            - å¸‚åœºææ…ŒæŒ‡æ•° (VIX): {vix_str} (Change: {vix_change_str})

            ## 1. æ ‡çš„åŸºæœ¬é¢ä¸è´¨é‡ (Quality & Value)
            - æ ‡çš„: {ticker} ({fund['name']}) | è¡Œä¸š: {fund['sector']}
            - ä¸šåŠ¡æ¦‚è§ˆ (10-K): {fund['business_summary'][:400]}...
            - æ ¸å¿ƒä¼°å€¼: P/E: {fund['pe']} | Fwd P/E: {fund['forward_pe']} | PEG: {fund['peg_ratio']} | P/B: {fund['pb']}
            - ç›ˆåˆ©è´¨é‡: ROE: {fund['roe']} | å‡€åˆ©ç‡: {fund['profit_margins']} | EPS: {fund['eps']}
            - è´¢åŠ¡æ æ†: è´Ÿå€ºæƒç›Šæ¯”: {fund['debt_to_equity']} | Beta: {fund['beta']}

            ## 2. é‡åŒ–ä¸æŠ€æœ¯é¢ (Quant & Technicals)
            - è¶‹åŠ¿æŒ‡æ ‡: 50D SMA: {latest['SMA_50']:.2f} | 200D SMA: {latest['SMA_200']:.2f}
            - åŠ¨èƒ½æŒ‡æ ‡: RSI: {latest['RSI']:.2f} | MACD: {latest['MACD']:.2f} (Signal: {latest['MACD_Signal']:.2f})
            - Aè‚¡ç‰¹è‰²æŒ‡æ ‡: KDJ: K={latest['K']:.1f} D={latest['D']:.1f} J={latest['J']:.1f}
            - é£é™©ä¸æ´»è·ƒåº¦: ATR(14): {latest['ATR']:.2f} | æ¢æ‰‹ç‡: {fund.get('turnover_rate', 'N/A')}
            - æ³¢åŠ¨ç‡: 30æ—¥å¹´åŒ–æ³¢åŠ¨ç‡: {latest['Volatility']:.2%}
            - å¸ƒæ—å¸¦ä½ç½®: Upper: {latest['BB_Upper']:.2f} | Lower: {latest['BB_Lower']:.2f} | Close: {latest['Close']:.2f}

            ## 3. è¡ç”Ÿå“ä¸æƒ…ç»ª (Derivatives & Sentiment)
            - æœŸæƒ Put/Call Ratio (Volume): {fund['pc_ratio_vol']} (åŸºäºæœ€è¿‘åˆ°æœŸæ—¥ {fund['options_expiry']})
            - æœŸæƒ Put/Call Ratio (Open Interest): {fund['pc_ratio_oi']}
            - ç©ºå¤´æµé€šå æ¯” (Short Float): {fund['short_percent']}
            {gex_info}
            
            ## 4. èµ„é‡‘æµå‘ä¸èªæ˜é’± (Smart Money Flow)
            - å¼‚å¸¸æœŸæƒå¼‚åŠ¨ (Unusual Whales - Vol > OI):
            {flow_info}

            ## 5. å¸‚åœºå‚¬åŒ–å‰‚ã€ç®¡ç†å±‚æŒ‡å¼•ä¸äº¤æ˜“å‘˜æƒ…ç»ª (Catalysts, Guidance & Sentiment)
            - ä¸‹æ¬¡è´¢æŠ¥æ—¥æœŸ: {fund.get('next_earnings', 'N/A')} (è·ç¦»ç°åœ¨ {fund.get('days_to_earnings', 'N/A')} å¤©)
            - å®æ—¶ç½‘ç»œæœç´¢ (å«æœªæ¥äº‹ä»¶ã€IVåˆ†æã€X/Twitterè®¨è®º):
            {web_content if web_content else "- æš‚æ— ç½‘ç»œæœç´¢ç»“æœ"}
            - äº¤æ˜“æ‰€æ–°é—» (Exchange News): 
            {news_headlines if news_headlines else "- æš‚æ— äº¤æ˜“æ‰€æ–°é—»"}

            ## 6. è´¢åŠ¡æŠ¥è¡¨é€è§† (Financials - Latest Quarter)
            - æŠ¥å‘Šæ—¥æœŸ: {fund['financials'].get('date', 'N/A')}
            - æ€»è¥æ”¶: {fund['financials'].get('revenue', 'N/A')} | å‡€åˆ©æ¶¦: {fund['financials'].get('net_income', 'N/A')}
            - æ¯›åˆ©æ¶¦: {fund['financials'].get('gross_profit', 'N/A')} | ç»è¥ç°é‡‘æµ: {fund['financials'].get('op_cashflow', 'N/A')}
            - èµ„äº§è´Ÿå€º: ç°é‡‘å‚¨å¤‡ {fund['financials'].get('total_cash', 'N/A')} vs æ€»å€ºåŠ¡ {fund['financials'].get('total_debt', 'N/A')}

            ## 7. åå°”è¡—åˆ†æå¸ˆå…±è¯† (Analyst Consensus)
            - ç»¼åˆè¯„çº§: {fund['analyst']['recommendation']} (åŸºäº {fund['analyst']['num_analysts']} ä½åˆ†æå¸ˆ)
            - ç›®æ ‡ä»·: Mean: {fund['analyst']['target_mean']} | High: {fund['analyst']['target_high']} | Low: {fund['analyst']['target_low']}
            - è¿‘æœŸæœºæ„è¯„çº§å˜åŠ¨:
            {analyst_ratings_str}
            """
        
        response = client.chat.completions.create(
            model=MODEL_ID,
            messages=[{"role": "user", "content": prompt}],
            stream=False
        )
        return response.choices[0].message.content
    @staticmethod
    async def get_ai_analysis(ticker, fund, tech_data, news_data, web_search_data, gex_data, flow_data, macro_data):
        """è°ƒç”¨ LLM ç”Ÿæˆæ›´æ·±åº¦çš„è‡ªç„¶è¯­è¨€æŠ¥å‘Š (Async Wrapper)"""
        try:
            loop = asyncio.get_running_loop()
            # å¤ç”¨åŒæ­¥ç”Ÿæˆæ–¹æ³•
            return await loop.run_in_executor(
                None, 
                lambda: StockAnalyzer._generate_ai_report_sync(ticker, fund, tech_data, news_data, web_search_data, gex_data, flow_data, macro_data)
            )
        except Exception as e:
            return f"AI åˆ†æç”Ÿæˆå¤±è´¥: {str(e)}"

# ================= Discord å‘½ä»¤å¤„ç† =================

@bot.event
async def on_ready():
    print(f'âœ… Bot å·²ç™»å½•: {bot.user}')
    if DISCORD_AI_REPORT_CHANNEL_ID:
        print(f'ğŸ”’ é¢‘é“é™åˆ¶å·²å¯ç”¨: ä»…åœ¨é¢‘é“ ID {DISCORD_AI_REPORT_CHANNEL_ID} å“åº”')
    print('DeepSeek æ¨¡å¼å°±ç»ªã€‚å°è¯•è¾“å…¥: !a TSLA')

@bot.command(name='a', aliases=['analyze', 'stock', 'gp'])
async def analyze(ctx, ticker: str):
    """
    åˆ†æè‚¡ç¥¨å‘½ä»¤ã€‚ç”¨æ³•: !a TSLA æˆ– !a 600519
    """
    # === é¢‘é“é™åˆ¶æ£€æŸ¥ ===
    if DISCORD_AI_REPORT_CHANNEL_ID and str(ctx.channel.id) != str(DISCORD_AI_REPORT_CHANNEL_ID):
        target_channel = bot.get_channel(int(DISCORD_AI_REPORT_CHANNEL_ID))
        channel_name = target_channel.name if target_channel else "æŒ‡å®šé¢‘é“"
        await ctx.send(f"âš ï¸ è¯·åœ¨æŒ‡å®šé¢‘é“ #{channel_name} ä½¿ç”¨æ­¤å‘½ä»¤ã€‚", delete_after=10)
        return

    ticker = ticker.upper()
    
    # === Aè‚¡ä»£ç è‡ªåŠ¨åç¼€è¡¥å…¨ ===
    if ticker.isdigit() and len(ticker) == 6:
        if ticker.startswith('6'):
            ticker = f"{ticker}.SS" # ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€
        elif ticker.startswith(('0', '3')):
            ticker = f"{ticker}.SZ" # æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€
        elif ticker.startswith(('4', '8')):
            ticker = f"{ticker}.BJ" # åŒ—äº¬è¯åˆ¸äº¤æ˜“æ‰€

    status_msg = await ctx.send(f"ğŸ” æ­£åœ¨åˆ†æ **{ticker}**ï¼Œè¯·ç¨å€™...")
    
    try:
        # 1. è·å–æ•°æ®
        await status_msg.edit(content=f"ğŸ§  æ­£åœ¨è·å– **{ticker}** çš„åŸºæœ¬é¢ã€æ–°é—»å’Œå†å²æ•°æ®...")
        df, fund, news, macro_data = StockAnalyzer.get_data(ticker)
        
        if df is None:
            await status_msg.edit(content=f"âŒ æ‰¾ä¸åˆ°è‚¡ç¥¨ä»£ç  **{ticker}**ï¼Œè¯·æ£€æŸ¥æ‹¼å†™æˆ–é‡è¯•ã€‚")
            return

        # è®¡ç®—æ¶¨è·Œå¹…
        price_change = 0
        if len(df) >= 2:
            price_change = (df['Close'].iloc[-1] - df['Close'].iloc[-2]) / df['Close'].iloc[-2]

        # 2. è®¡ç®—æŒ‡æ ‡
        await status_msg.edit(content=f"ğŸ“ˆ æ­£åœ¨è®¡ç®— **{ticker}** çš„æŠ€æœ¯æŒ‡æ ‡ä¸é‡åŒ–ä¿¡å·...")
        df_tech = StockAnalyzer.calculate_indicators(df)
        
        # 3. æ‰§è¡Œç½‘ç»œæœç´¢ (åœ¨åå°çº¿ç¨‹è¿è¡Œä»¥é˜²é˜»å¡)
        loop = asyncio.get_running_loop()
        web_results = await loop.run_in_executor(None, lambda: StockAnalyzer.get_web_search(ticker))

        # 4. åˆå§‹åŒ– Ticker å¯¹è±¡ (å¤ç”¨ä»¥æé«˜æ•ˆç‡)
        stock_obj = yf.Ticker(ticker)

        # 5. è®¡ç®— Gamma Exposure (GEX)
        await status_msg.edit(content=f"ğŸ§® æ­£åœ¨è®¡ç®— **{ticker}** çš„ Gamma Exposure (GEX) ä¸æŒ¤å‹é£é™©...")
        gex_data = await loop.run_in_executor(None, lambda: StockAnalyzer.get_gamma_exposure(stock_obj, fund['price']))

        # 6. æ‰«ææœŸæƒèµ„é‡‘æµ (Option Flow)
        await status_msg.edit(content=f"ğŸ’¸ æ­£åœ¨æ‰«æ **{ticker}** çš„æœŸæƒèµ„é‡‘æµä¸èªæ˜é’±å¸ƒå±€...")
        flow_data = await loop.run_in_executor(None, lambda: StockAnalyzer.get_option_flow(stock_obj, fund['price']))

        # 7. ç”ŸæˆæœŸæƒ OI å›¾è¡¨
        oi_chart_buffer = await loop.run_in_executor(None, lambda: StockAnalyzer.get_option_open_interest_chart(stock_obj, fund['price']))

        # æ–°å¢: ä¸Šä¼ å›¾è¡¨åˆ° Supabase ä»¥è·å– URL
        oi_chart_url = None
        if oi_chart_buffer and supabase:
            oi_chart_filename = f"{ticker}_oi_chart_{int(time.time())}.png"
            oi_chart_url = await loop.run_in_executor(None, lambda: StockAnalyzer.upload_file_to_supabase(oi_chart_filename, oi_chart_buffer, "image/png"))

        # 8. è·å– AI æŠ¥å‘Š
        await status_msg.edit(content=f"ğŸ¤– DeepSeek R1 (æ·±åº¦æ€è€ƒæ¨¡å¼) æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        report = await StockAnalyzer.get_ai_analysis(ticker, fund, df_tech, news, web_results, gex_data, flow_data, macro_data)

        # 9. æ„å»º Embed æ¶ˆæ¯
        embed = discord.Embed(
            title=f"ğŸ“‘ {ticker} æ·±åº¦æŠ•èµ„åˆ†ææŠ¥å‘Š",
            description=report,
            color=0x1a73e8 # Google Blue
        )
        
        latest = df_tech.iloc[-1]
        embed.add_field(name="å½“å‰ä»·æ ¼", value=f"{fund['price']}", inline=True)
        embed.add_field(name="P/E ä¼°å€¼", value=f"{fund['pe']}", inline=True)
        embed.add_field(name="P/B ä¼°å€¼", value=f"{fund['pb']}", inline=True)
        embed.add_field(name="RSI (14)", value=f"{latest['RSI']:.1f}", inline=True)
        embed.add_field(name="æ³¢åŠ¨ç‡", value=f"{latest['Volatility']:.2%}", inline=True)
        embed.add_field(name="P/C Ratio (Vol)", value=f"{fund['pc_ratio_vol']}", inline=True)
        if gex_data:
            embed.add_field(name="Call Wall (é˜»åŠ›)", value=f"{gex_data['call_wall']}", inline=True)
            embed.add_field(name="Put Wall (æ”¯æ’‘)", value=f"{gex_data['put_wall']}", inline=True)
        if flow_data:
            top_flow = flow_data[0]
            embed.add_field(name="æœ€å¤§å¼‚åŠ¨", value=f"{top_flow['type']} {top_flow['strike']} (Vol:{top_flow['volume']})", inline=True)
        embed.add_field(name="è¶‹åŠ¿ (50/200)", value=f'{"é‡‘å‰" if latest["SMA_50"] > latest["SMA_200"] else "æ­»å‰"}', inline=True)

        # å°† OI å›¾è¡¨ç›´æ¥åµŒå…¥æ¶ˆæ¯
        if oi_chart_url:
            embed.set_image(url=oi_chart_url)

        embed.set_footer(text=f"åˆ†æå¯¹è±¡: {fund['name']} | Host: {socket.gethostname()} | ç”± DeepSeek AI å¼ºåŠ›é©±åŠ¨")
        embed.set_thumbnail(url="https://cdn-icons-png.flaticon.com/512/8569/8569731.png") # ä¸€ä¸ªä¸­æ€§çš„å›¾è¡¨icon

        # 10. ç”Ÿæˆ PDF å¹¶å‘é€
        pdf_file = None
        pdf_buffer = StockAnalyzer.create_pdf_report(ticker, report, fund, latest, price_change, oi_chart_buffer)
        if pdf_buffer:
            pdf_file = discord.File(pdf_buffer, filename=f"{ticker}_Analysis.pdf")

        # 11. å‘é€ç»“æœ
        await status_msg.edit(content="", embed=embed, attachments=[pdf_file] if pdf_file else [])

    except Exception as e:
        error_message = f"âŒ å¤„ç† **{ticker}** æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}\n"
        error_message += "è¿™å¯èƒ½æ˜¯ç”±äºæ•°æ®æºé—®é¢˜æˆ–å†…éƒ¨è®¡ç®—é”™è¯¯ã€‚è¯·ç¨åå†è¯•ã€‚"
        await status_msg.edit(content=error_message)

# å¯åŠ¨ Bot
if __name__ == "__main__":
    if not DISCORD_TOKEN or not DEEPSEEK_API_KEY:
        print("âš ï¸ è¯·è®¾ç½® DISCORD_TOKEN å’Œ DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
    else:
        # ä½¿ç”¨ asyncio åŒæ—¶è¿è¡Œ discord bot å’Œ fastapi server
        async def main():
            # å¯åŠ¨ discord bot ä½œä¸ºåå°ä»»åŠ¡
            bot_task = asyncio.create_task(bot.start(DISCORD_TOKEN))
            
            # é…ç½® uvicorn
            port = int(os.getenv('PORT', 8000))
            config = uvicorn.Config(app, host="0.0.0.0", port=port, log_level="info")
            server = uvicorn.Server(config)
            
            # å¯åŠ¨ fastapi server
            server_task = asyncio.create_task(server.serve())
            
            # ç­‰å¾…ä¸¤ä¸ªä»»åŠ¡å®Œæˆ
            await asyncio.gather(
                bot_task,
                server_task
            )

        asyncio.run(main())